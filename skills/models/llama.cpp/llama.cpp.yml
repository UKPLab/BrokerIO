name: Llama.cpp
path: ./llama.cpp
model_path: ./llama.cpp/model/llama-model.gguf
debug_level: INFO
num_threads: 30
num_ctx: 1024
skill:
    name: LLM
    description: Prompt based text generation
    input:
        data:
        text:
            type: string
            required: true
            description: Prompt
        max_length:
            type: integer
            required: false
            description: Maximum length of the generated text
        stop:
            type: array
            required: false
            description: Stop tokens
        echo:
            type: boolean
            required: false
            description: Echo prompt in generated text
        example: {text: "This is a test!"}
    output:
        data:
        response:
            type: string
            description: Generated text
        example: {"response": "Dies ist ein Test!"}